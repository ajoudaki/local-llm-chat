# Per-model config for Qwen3-30B-A3B-Thinking (MoE: 30B total, 3B active)
# These settings override the global config when loading via inline_model_loading

model:
  tensor_parallel: true
  gpu_split_auto: false
  gpu_split: [12, 12]
  max_seq_len: -1
  cache_size: 65536
  cache_mode: Q8
